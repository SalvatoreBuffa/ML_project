{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0799eb0fd45bbf32cd22b7eb12315f66a6945dddec75ab4ee4de6611b037c6c79",
   "display_name": "Python 3.8.5 64-bit ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "799eb0fd45bbf32cd22b7eb12315f66a6945dddec75ab4ee4de6611b037c6c79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dropout, Dense, Input, Bidirectional\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import string\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open(\"dataset/IMDB/dataset_IMDB.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, dataset[\"sentiment\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(dataset[\"processed_review\"],Y, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creazione_modello_GloVe(filename):\n",
    "    f = open(filename, encoding=\"utf8\")\n",
    "    embeding_index = {}\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embeding_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = creazione_modello_GloVe(\"dataset/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=142092)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(word_index)+1\n",
    "embedding_vector_len = embedding[\"banan\"].shape[0]\n",
    "embedding_matrix = np.zeros((vocab_len, embedding_vector_len))\n",
    "\n",
    "for word, index in word_index.items():\n",
    "    vector = embedding.get(word)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[index, :] = vector\n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embedding_vector_len, input_length=200, weights=[embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 200, 50)           5007800   \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 64)                21248     \n_________________________________________________________________\ndense_6 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_7 (Dense)              (None, 32)                1056      \n_________________________________________________________________\ndense_8 (Dense)              (None, 2)                 66        \n=================================================================\nTotal params: 5,032,250\nTrainable params: 5,032,250\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Bi_LSTM_model = Sequential()\n",
    "Bi_LSTM_model.add(embedding_layer)\n",
    "Bi_LSTM_model.add(Bidirectional(LSTM(units=32)))\n",
    "Bi_LSTM_model.add(Dense(32))\n",
    "Bi_LSTM_model.add(Dense(32))\n",
    "Bi_LSTM_model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "#non è necessario modificare l'ottimizzatore di default, poichè già lr=0.001\n",
    "Bi_LSTM_model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.05), metrics=[\"accuracy\"])\n",
    "Bi_LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(45000,) (45000,)\n(5000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_index = tokenizer.texts_to_sequences(x_train)\n",
    "x_train_index = pad_sequences(x_train_index, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = keras.utils.to_categorical(y_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "274/274 [==============================] - 55s 193ms/step - loss: 0.6067 - accuracy: 0.6944 - val_loss: 0.4611 - val_accuracy: 0.8056\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 54s 196ms/step - loss: 0.3854 - accuracy: 0.8403 - val_loss: 0.4733 - val_accuracy: 0.7906\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 55s 201ms/step - loss: 0.3438 - accuracy: 0.8591 - val_loss: 0.4860 - val_accuracy: 0.7924\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 55s 203ms/step - loss: 0.3119 - accuracy: 0.8754 - val_loss: 0.5380 - val_accuracy: 0.7949\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 56s 205ms/step - loss: 0.3049 - accuracy: 0.8759 - val_loss: 0.5737 - val_accuracy: 0.7656\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 56s 206ms/step - loss: 0.3114 - accuracy: 0.8730 - val_loss: 0.5470 - val_accuracy: 0.7712\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 57s 207ms/step - loss: 0.3208 - accuracy: 0.8665 - val_loss: 0.5379 - val_accuracy: 0.7754\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 57s 208ms/step - loss: 0.3134 - accuracy: 0.8732 - val_loss: 0.5571 - val_accuracy: 0.7740\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 59s 215ms/step - loss: 0.2841 - accuracy: 0.8870 - val_loss: 0.5349 - val_accuracy: 0.7837\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 54s 196ms/step - loss: 0.4764 - accuracy: 0.8729 - val_loss: 6.5235 - val_accuracy: 0.7157\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f31f869b9d0>"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "Bi_LSTM_model.fit(x_train_index[:35000], y_train_categorical[:35000], epochs=10, batch_size=128, verbose=1, validation_data=(x_train_index[35000:], y_train_categorical[35000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_index = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_index = pad_sequences(x_test_index, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Bi_LSTM_model.predict(x_test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.78      0.59      0.67      2525\n           1       0.67      0.83      0.74      2475\n\n    accuracy                           0.71      5000\n   macro avg       0.72      0.71      0.71      5000\nweighted avg       0.73      0.71      0.71      5000\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, np.argmax(y_pred, axis=1).astype(\"float32\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_7_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: IMDB_BiLSTM/assets\n",
      "INFO:tensorflow:Assets written to: IMDB_BiLSTM/assets\n"
     ]
    }
   ],
   "source": [
    "Bi_LSTM_model.save(\"IMDB_BiLSTM\")"
   ]
  }
 ]
}