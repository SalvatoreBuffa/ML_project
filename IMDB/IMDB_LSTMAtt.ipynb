{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0799eb0fd45bbf32cd22b7eb12315f66a6945dddec75ab4ee4de6611b037c6c79",
   "display_name": "Python 3.8.5 64-bit ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "799eb0fd45bbf32cd22b7eb12315f66a6945dddec75ab4ee4de6611b037c6c79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, Activation, Dropout, Dense, Input, Layer\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model, Sequential\n",
    "import string\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "import keras.backend as kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open(\"dataset/IMDB/dataset_IMDB.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, dataset[\"sentiment\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(dataset[\"processed_review\"],Y, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creazione_modello_GloVe(filename):\n",
    "    f = open(filename, encoding=\"utf8\")\n",
    "    embeding_index = {}\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embeding_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = creazione_modello_GloVe(\"dataset/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=142092)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(word_index)+1\n",
    "embedding_vector_len = embedding[\"banan\"].shape[0]\n",
    "embedding_matrix = np.zeros((vocab_len, embedding_vector_len))\n",
    "\n",
    "for word, index in word_index.items():\n",
    "    vector = embedding.get(word)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[index, :] = vector\n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embedding_vector_len, input_length=200, weights=[embedding_matrix])"
   ]
  },
  {
   "source": [
    "## Creazione classe ad-hoc per implementare il meccanismo di attention"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=kb.squeeze(kb.tanh(kb.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=kb.softmax(et)\n",
    "        at=kb.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return kb.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 200, 50)           5009900   \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 200, 16)           4288      \n_________________________________________________________________\nattention_2 (attention)      (None, 16)                216       \n_________________________________________________________________\ndense (Dense)                (None, 2)                 34        \n=================================================================\nTotal params: 5,014,438\nTrainable params: 5,014,438\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstmAtt_model = Sequential()\n",
    "lstmAtt_model.add(embedding_layer)\n",
    "lstmAtt_model.add(LSTM(16, return_sequences=True))\n",
    "lstmAtt_model.add(attention())\n",
    "lstmAtt_model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "lstmAtt_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adagrad\", metrics=[\"accuracy\"])\n",
    "lstmAtt_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_index = tokenizer.texts_to_sequences(x_train)\n",
    "x_train_index = pad_sequences(x_train_index, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = keras.utils.to_categorical(y_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1094/1094 [==============================] - 79s 60ms/step - loss: 0.6950 - accuracy: 0.5200 - val_loss: 0.6855 - val_accuracy: 0.5767\n",
      "Epoch 2/10\n",
      "1094/1094 [==============================] - 65s 59ms/step - loss: 0.6843 - accuracy: 0.5909 - val_loss: 0.6808 - val_accuracy: 0.6219\n",
      "Epoch 3/10\n",
      "1094/1094 [==============================] - 65s 59ms/step - loss: 0.6802 - accuracy: 0.6257 - val_loss: 0.6760 - val_accuracy: 0.6547\n",
      "Epoch 4/10\n",
      "1094/1094 [==============================] - 65s 60ms/step - loss: 0.6750 - accuracy: 0.6606 - val_loss: 0.6697 - val_accuracy: 0.6853\n",
      "Epoch 5/10\n",
      "1094/1094 [==============================] - 65s 59ms/step - loss: 0.6679 - accuracy: 0.6933 - val_loss: 0.6607 - val_accuracy: 0.7079\n",
      "Epoch 6/10\n",
      "1094/1094 [==============================] - 63s 58ms/step - loss: 0.6586 - accuracy: 0.7008 - val_loss: 0.6469 - val_accuracy: 0.7122\n",
      "Epoch 7/10\n",
      "1094/1094 [==============================] - 69s 63ms/step - loss: 0.6427 - accuracy: 0.7105 - val_loss: 0.6279 - val_accuracy: 0.7127\n",
      "Epoch 8/10\n",
      "1094/1094 [==============================] - 69s 63ms/step - loss: 0.6233 - accuracy: 0.7132 - val_loss: 0.6092 - val_accuracy: 0.7147\n",
      "Epoch 9/10\n",
      "1094/1094 [==============================] - 69s 63ms/step - loss: 0.6113 - accuracy: 0.7047 - val_loss: 0.5967 - val_accuracy: 0.7151\n",
      "Epoch 10/10\n",
      "1094/1094 [==============================] - 70s 64ms/step - loss: 0.5983 - accuracy: 0.7124 - val_loss: 0.5888 - val_accuracy: 0.7192\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb51037bbe0>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "lstmAtt_model.fit(x_train_index[:35000], y_train_categorical[:35000], epochs=10, batch_size=32, verbose=1, validation_data=(x_train_index[35000:], y_train_categorical[35000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_index = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_index = pad_sequences(x_test_index, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstmAtt_model.predict(x_test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.73      0.69      0.71      2558\n           1       0.69      0.73      0.71      2442\n\n    accuracy                           0.71      5000\n   macro avg       0.71      0.71      0.71      5000\nweighted avg       0.71      0.71      0.71      5000\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, np.argmax(y_pred, axis=1).astype(\"float32\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: IMDB_LSTMAtt/assets\n",
      "INFO:tensorflow:Assets written to: IMDB_LSTMAtt/assets\n"
     ]
    }
   ],
   "source": [
    "lstmAtt_model.save(\"IMDB_LSTMAtt\")"
   ]
  }
 ]
}