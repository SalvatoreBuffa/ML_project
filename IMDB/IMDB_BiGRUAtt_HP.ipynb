{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0799eb0fd45bbf32cd22b7eb12315f66a6945dddec75ab4ee4de6611b037c6c79",
   "display_name": "Python 3.8.5  ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "799eb0fd45bbf32cd22b7eb12315f66a6945dddec75ab4ee4de6611b037c6c79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Embedding, GRU, Activation, Dropout, Dense, Input, Bidirectional, Layer\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.activations import tanh\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras.backend as kb\n",
    "import tensorflow\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open(\"dataset/dataset_IMDB.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, dataset[\"sentiment\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(dataset[\"processed_review\"],Y, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numero di positivi nel train:  22479\nnumero di negativi nel train:  22521\nnumero di positivi nel test:  2521\nnumero di negativi nel test:  2479\n"
     ]
    }
   ],
   "source": [
    "print(\"numero di positivi nel train: \", list(y_train).count(1))\n",
    "print(\"numero di negativi nel train: \", list(y_train).count(0))\n",
    "\n",
    "print(\"numero di positivi nel test: \", list(y_test).count(1))\n",
    "print(\"numero di negativi nel test: \", list(y_test).count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creazione_modello_GloVe(filename):\n",
    "    f = open(filename, encoding=\"utf8\")\n",
    "    embeding_index = {}\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embeding_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = creazione_modello_GloVe(\"dataset/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=142092)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(word_index)+1\n",
    "embedding_vector_len = embedding[\"banana\"].shape[0]\n",
    "embedding_matrix = np.zeros((vocab_len, embedding_vector_len))\n",
    "\n",
    "for word, index in word_index.items():\n",
    "    vector = embedding.get(word)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[index, :] = vector\n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embedding_vector_len, input_length=200, weights=[embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=kb.squeeze(kb.tanh(kb.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=kb.softmax(et)\n",
    "        at=kb.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return kb.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete([\"adam\", \"sgd\", \"rmsprop\"]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.1,0.2, 0.3, 0.5]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32, 64]))\n",
    "\n",
    "log_dir = 'logs/IMDB_BiGRUAtt_HP'\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tensorflow.summary.create_file_writer(log_dir).as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name=\"Accuracy\")],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(45000,) (45000,)\n(5000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_index = tokenizer.texts_to_sequences(x_train)\n",
    "x_train_index = pad_sequences(x_train_index, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(45000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = keras.utils.to_categorical(y_train, 2)\n",
    "y_test_categorical = keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(45000, 2)\n(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_categorical.shape)\n",
    "print(y_test_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_index = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_index = pad_sequences(x_test_index, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    model = Sequential([\n",
    "        embedding_layer,\n",
    "        Bidirectional(GRU(units=hparams[HP_NUM_UNITS], return_sequences=True, dropout=hparams[HP_DROPOUT])),\n",
    "        Dense(hparams[HP_NUM_UNITS]),\n",
    "        Dense(hparams[HP_NUM_UNITS]),\n",
    "        attention(),\n",
    "        Dense(2, activation=\"sigmoid\"),\n",
    "    ])\n",
    "    model.compile(optimizer=hparams[HP_OPTIMIZER], loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(x_train_index[:35000], y_train_categorical[:35000], epochs=10, batch_size=128, verbose=1, validation_data=(x_train_index[35000:], y_train_categorical[35000:]), callbacks=[tensorflow.keras.callbacks.TensorBoard(log_dir), hp.KerasCallback(log_dir, hparams)])\n",
    "    _, accuracy = model.evaluate(x_test_index, y_test_categorical)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tensorflow.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        accuracy = train_test_model(hparams)\n",
    "        tensorflow.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "esecuzione:  25\n",
      "{'dropout': 0.1, 'num_units': 64, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 177s 615ms/step - loss: 0.4144 - accuracy: 0.8105 - val_loss: 0.3183 - val_accuracy: 0.8629\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 170s 620ms/step - loss: 0.2565 - accuracy: 0.8932 - val_loss: 0.2839 - val_accuracy: 0.8814\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 173s 633ms/step - loss: 0.1901 - accuracy: 0.9251 - val_loss: 0.2980 - val_accuracy: 0.8782\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 177s 647ms/step - loss: 0.1315 - accuracy: 0.9503 - val_loss: 0.3321 - val_accuracy: 0.8821\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 181s 659ms/step - loss: 0.0722 - accuracy: 0.9751 - val_loss: 0.3860 - val_accuracy: 0.8840\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 183s 668ms/step - loss: 0.0380 - accuracy: 0.9868 - val_loss: 0.5347 - val_accuracy: 0.8776\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 186s 678ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.5852 - val_accuracy: 0.8815\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 187s 683ms/step - loss: 0.0132 - accuracy: 0.9950 - val_loss: 0.7675 - val_accuracy: 0.8655\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 186s 678ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 0.8042 - val_accuracy: 0.8755\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 192s 702ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.8247 - val_accuracy: 0.8679\n",
      "157/157 [==============================] - 10s 64ms/step - loss: 0.8016 - accuracy: 0.8732\n",
      "esecuzione:  26\n",
      "{'dropout': 0.1, 'num_units': 64, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 217s 752ms/step - loss: 0.2102 - accuracy: 0.9114 - val_loss: 0.3642 - val_accuracy: 0.8799\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 192s 699ms/step - loss: 0.0617 - accuracy: 0.9780 - val_loss: 0.8397 - val_accuracy: 0.8241\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 181s 662ms/step - loss: 0.0278 - accuracy: 0.9896 - val_loss: 0.6669 - val_accuracy: 0.8745\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 184s 673ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.7504 - val_accuracy: 0.8739\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 179s 652ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.9138 - val_accuracy: 0.8756\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 178s 649ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.9562 - val_accuracy: 0.8705\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 116s 423ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.9034 - val_accuracy: 0.8746\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 120s 438ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 1.1418 - val_accuracy: 0.8728\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 121s 443ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 1.2663 - val_accuracy: 0.8699\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 120s 439ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 1.2786 - val_accuracy: 0.8668\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 1.2356 - accuracy: 0.8768\n",
      "esecuzione:  27\n",
      "{'dropout': 0.1, 'num_units': 64, 'optimizer': 'sgd'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 131s 452ms/step - loss: 0.6844 - accuracy: 0.6477 - val_loss: 0.6782 - val_accuracy: 0.7143\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 118s 431ms/step - loss: 0.6663 - accuracy: 0.7961 - val_loss: 0.6581 - val_accuracy: 0.7980\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 118s 429ms/step - loss: 0.6322 - accuracy: 0.8449 - val_loss: 0.6130 - val_accuracy: 0.8144\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 118s 432ms/step - loss: 0.5486 - accuracy: 0.8623 - val_loss: 0.5073 - val_accuracy: 0.8296\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 118s 432ms/step - loss: 0.4003 - accuracy: 0.8828 - val_loss: 0.3932 - val_accuracy: 0.8448\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 117s 428ms/step - loss: 0.2785 - accuracy: 0.9059 - val_loss: 0.3453 - val_accuracy: 0.8502\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 116s 423ms/step - loss: 0.2022 - accuracy: 0.9309 - val_loss: 0.3220 - val_accuracy: 0.8614\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 114s 415ms/step - loss: 0.1518 - accuracy: 0.9487 - val_loss: 0.3305 - val_accuracy: 0.8660\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 115s 418ms/step - loss: 0.1187 - accuracy: 0.9590 - val_loss: 0.3430 - val_accuracy: 0.8698\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 114s 416ms/step - loss: 0.0968 - accuracy: 0.9649 - val_loss: 0.3797 - val_accuracy: 0.8673\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.3527 - accuracy: 0.8770\n",
      "esecuzione:  28\n",
      "{'dropout': 0.2, 'num_units': 64, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 140s 483ms/step - loss: 0.1246 - accuracy: 0.9505 - val_loss: 0.5360 - val_accuracy: 0.8723\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 127s 462ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.6724 - val_accuracy: 0.8722\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 127s 463ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.8568 - val_accuracy: 0.8651\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 126s 461ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.8779 - val_accuracy: 0.8657\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 126s 460ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.9751 - val_accuracy: 0.8712\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 130s 475ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 1.1694 - val_accuracy: 0.8584\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 131s 479ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 1.2872 - val_accuracy: 0.8495\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 134s 490ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 1.1307 - val_accuracy: 0.8686\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 127s 462ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 1.3758 - val_accuracy: 0.8661\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 126s 460ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 1.1656 - val_accuracy: 0.8638\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 1.1406 - accuracy: 0.8762\n",
      "esecuzione:  29\n",
      "{'dropout': 0.2, 'num_units': 64, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 137s 474ms/step - loss: 0.1251 - accuracy: 0.9504 - val_loss: 0.6595 - val_accuracy: 0.8734\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 120s 439ms/step - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.9305 - val_accuracy: 0.8726\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 116s 424ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.9927 - val_accuracy: 0.8620\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 116s 424ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.9466 - val_accuracy: 0.8678\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 111s 404ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 1.2130 - val_accuracy: 0.8703\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 73s 266ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 1.3529 - val_accuracy: 0.8664\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 122s 444ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 1.5850 - val_accuracy: 0.8671\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 121s 441ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 1.6048 - val_accuracy: 0.8666\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 121s 444ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 1.4650 - val_accuracy: 0.8679\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 121s 441ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.7170 - val_accuracy: 0.8691\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 1.6687 - accuracy: 0.8732\n",
      "esecuzione:  30\n",
      "{'dropout': 0.2, 'num_units': 64, 'optimizer': 'sgd'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 131s 450ms/step - loss: 0.6900 - accuracy: 0.5691 - val_loss: 0.6812 - val_accuracy: 0.6852\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 117s 428ms/step - loss: 0.6651 - accuracy: 0.8055 - val_loss: 0.6510 - val_accuracy: 0.8108\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 117s 427ms/step - loss: 0.6073 - accuracy: 0.8721 - val_loss: 0.5683 - val_accuracy: 0.8295\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 117s 426ms/step - loss: 0.4660 - accuracy: 0.8967 - val_loss: 0.4238 - val_accuracy: 0.8455\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 116s 423ms/step - loss: 0.2967 - accuracy: 0.9201 - val_loss: 0.3372 - val_accuracy: 0.8595\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 117s 429ms/step - loss: 0.1966 - accuracy: 0.9402 - val_loss: 0.3215 - val_accuracy: 0.8643\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 114s 417ms/step - loss: 0.1432 - accuracy: 0.9553 - val_loss: 0.3146 - val_accuracy: 0.8711\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 113s 413ms/step - loss: 0.1098 - accuracy: 0.9639 - val_loss: 0.3327 - val_accuracy: 0.8757\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 113s 413ms/step - loss: 0.0894 - accuracy: 0.9709 - val_loss: 0.3455 - val_accuracy: 0.8773\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 115s 419ms/step - loss: 0.0766 - accuracy: 0.9745 - val_loss: 0.3672 - val_accuracy: 0.8748\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.3328 - accuracy: 0.8842\n",
      "esecuzione:  31\n",
      "{'dropout': 0.3, 'num_units': 64, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 138s 476ms/step - loss: 0.0948 - accuracy: 0.9651 - val_loss: 0.7801 - val_accuracy: 0.8740\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 125s 455ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.8328 - val_accuracy: 0.8738\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 125s 455ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.9742 - val_accuracy: 0.8701\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 125s 456ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.1889 - val_accuracy: 0.8722\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 134s 488ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 1.0943 - val_accuracy: 0.8695\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 153s 560ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 1.1285 - val_accuracy: 0.8710\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 155s 565ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 1.1611 - val_accuracy: 0.8700\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 163s 594ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 1.3018 - val_accuracy: 0.8669\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 162s 591ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 1.1611 - val_accuracy: 0.8659\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 166s 605ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 1.4250 - val_accuracy: 0.8662\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 1.3913 - accuracy: 0.8726\n",
      "esecuzione:  32\n",
      "{'dropout': 0.3, 'num_units': 64, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 175s 599ms/step - loss: 0.1003 - accuracy: 0.9620 - val_loss: 0.7245 - val_accuracy: 0.8743\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 186s 681ms/step - loss: 0.0138 - accuracy: 0.9947 - val_loss: 1.0575 - val_accuracy: 0.8718\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 184s 671ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 2.5871 - val_accuracy: 0.8033\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 183s 669ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.5418 - val_accuracy: 0.8666\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 155s 564ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 1.5929 - val_accuracy: 0.8710\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 172s 628ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.6490 - val_accuracy: 0.8550\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 139s 507ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 1.7050 - val_accuracy: 0.8723\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 118s 432ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 1.4161 - val_accuracy: 0.8707\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 118s 432ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 1.4333 - val_accuracy: 0.8651\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 119s 433ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 1.3683 - val_accuracy: 0.8681\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 1.3219 - accuracy: 0.8754\n",
      "esecuzione:  33\n",
      "{'dropout': 0.3, 'num_units': 64, 'optimizer': 'sgd'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 131s 453ms/step - loss: 0.6919 - accuracy: 0.5575 - val_loss: 0.6817 - val_accuracy: 0.7307\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 118s 429ms/step - loss: 0.6672 - accuracy: 0.8338 - val_loss: 0.6547 - val_accuracy: 0.8329\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 118s 430ms/step - loss: 0.6164 - accuracy: 0.9017 - val_loss: 0.5772 - val_accuracy: 0.8540\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 120s 438ms/step - loss: 0.4726 - accuracy: 0.9176 - val_loss: 0.4134 - val_accuracy: 0.8611\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 117s 429ms/step - loss: 0.2866 - accuracy: 0.9336 - val_loss: 0.3235 - val_accuracy: 0.8664\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 97s 356ms/step - loss: 0.1842 - accuracy: 0.9477 - val_loss: 0.3070 - val_accuracy: 0.8713\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 119s 434ms/step - loss: 0.1330 - accuracy: 0.9599 - val_loss: 0.3180 - val_accuracy: 0.8759\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 124s 452ms/step - loss: 0.1030 - accuracy: 0.9685 - val_loss: 0.3289 - val_accuracy: 0.8773\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 116s 424ms/step - loss: 0.0830 - accuracy: 0.9736 - val_loss: 0.3412 - val_accuracy: 0.8803\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 116s 425ms/step - loss: 0.0681 - accuracy: 0.9794 - val_loss: 0.3690 - val_accuracy: 0.8761\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.3396 - accuracy: 0.8860\n",
      "esecuzione:  34\n",
      "{'dropout': 0.5, 'num_units': 64, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 141s 492ms/step - loss: 0.1035 - accuracy: 0.9585 - val_loss: 0.7575 - val_accuracy: 0.8755\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 127s 463ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 1.0373 - val_accuracy: 0.8600\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 126s 460ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.9419 - val_accuracy: 0.8688\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 127s 463ms/step - loss: 0.0105 - accuracy: 0.9956 - val_loss: 1.0293 - val_accuracy: 0.8672\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 127s 463ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 1.1005 - val_accuracy: 0.8632\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 84s 307ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 0.9658 - val_accuracy: 0.8723\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 126s 460ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.0184 - val_accuracy: 0.8715\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 126s 460ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 1.1188 - val_accuracy: 0.8735\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 126s 460ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 1.1209 - val_accuracy: 0.8716\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 126s 458ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 1.1377 - val_accuracy: 0.8709\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 1.0866 - accuracy: 0.8734\n",
      "esecuzione:  35\n",
      "{'dropout': 0.5, 'num_units': 64, 'optimizer': 'rmsprop'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 133s 457ms/step - loss: 0.0883 - accuracy: 0.9664 - val_loss: 0.7811 - val_accuracy: 0.8689\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 118s 429ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 1.1184 - val_accuracy: 0.8747\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 117s 425ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 1.1955 - val_accuracy: 0.8574\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 117s 427ms/step - loss: 0.0087 - accuracy: 0.9966 - val_loss: 1.1237 - val_accuracy: 0.8720\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 117s 427ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 1.0421 - val_accuracy: 0.8720\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 109s 398ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 1.3254 - val_accuracy: 0.8715\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 65s 236ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 1.4102 - val_accuracy: 0.8723\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 62s 227ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.1184 - val_accuracy: 0.8735\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 62s 227ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 1.3041 - val_accuracy: 0.8687\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 63s 229ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 1.3594 - val_accuracy: 0.8719\n",
      "157/157 [==============================] - 4s 25ms/step - loss: 1.2929 - accuracy: 0.8766\n",
      "esecuzione:  36\n",
      "{'dropout': 0.5, 'num_units': 64, 'optimizer': 'sgd'}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 71s 244ms/step - loss: 0.6801 - accuracy: 0.6611 - val_loss: 0.6650 - val_accuracy: 0.7775\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 61s 224ms/step - loss: 0.6381 - accuracy: 0.8635 - val_loss: 0.6040 - val_accuracy: 0.8411\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 62s 225ms/step - loss: 0.5247 - accuracy: 0.9083 - val_loss: 0.4499 - val_accuracy: 0.8562\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 61s 224ms/step - loss: 0.3311 - accuracy: 0.9309 - val_loss: 0.3356 - val_accuracy: 0.8609\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 61s 224ms/step - loss: 0.2017 - accuracy: 0.9478 - val_loss: 0.3061 - val_accuracy: 0.8710\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 61s 223ms/step - loss: 0.1389 - accuracy: 0.9607 - val_loss: 0.3105 - val_accuracy: 0.8776\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 61s 222ms/step - loss: 0.1046 - accuracy: 0.9696 - val_loss: 0.3257 - val_accuracy: 0.8800\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 61s 222ms/step - loss: 0.0832 - accuracy: 0.9751 - val_loss: 0.3439 - val_accuracy: 0.8815\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 61s 222ms/step - loss: 0.0690 - accuracy: 0.9784 - val_loss: 0.3637 - val_accuracy: 0.8807\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 61s 223ms/step - loss: 0.0581 - accuracy: 0.9819 - val_loss: 0.3847 - val_accuracy: 0.8809\n",
      "157/157 [==============================] - 4s 24ms/step - loss: 0.3550 - accuracy: 0.8846\n"
     ]
    }
   ],
   "source": [
    "n_esecuzione = 0\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "        for dropout in HP_DROPOUT.domain.values:\n",
    "            for opt in HP_OPTIMIZER.domain.values:\n",
    "                hparams = {\n",
    "                    HP_DROPOUT: dropout,\n",
    "                    HP_NUM_UNITS: num_units,\n",
    "                    HP_OPTIMIZER: opt,\n",
    "                    }\n",
    "                print(\"esecuzione: \", n_esecuzione)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                run(log_dir + \"/esecuzione_{}\".format(n_esecuzione), hparams)\n",
    "                n_esecuzione += 1"
   ]
  },
  {
   "source": [
    "Dopo aver constatato che la migliore configurazione è: \n",
    "Num_units: 16, dropout=0.1, opt=sgd con accuracy del 88% si è deciso di provare a modificare il learning rate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([0.005, 0.010, 0.015, 0.020, 0.050, 0.1]))\n",
    "\n",
    "log_dir = 'logs/IMDB_BiGRUAtt_LR'\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tensorflow.summary.create_file_writer(log_dir).as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_LEARNING_RATE],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name=\"Accuracy\")],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    model = Sequential([\n",
    "        embedding_layer,\n",
    "        Bidirectional(GRU(units=16, return_sequences=True, dropout=0.1)),\n",
    "        Dense(16),\n",
    "        Dense(16),\n",
    "        attention(),\n",
    "        Dense(2, activation=\"sigmoid\"),\n",
    "    ])\n",
    "    opt = SGD(learning_rate=hparams[HP_LEARNING_RATE])\n",
    "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(x_train_index[:35000], y_train_categorical[:35000], epochs=10, batch_size=128, verbose=1, validation_data=(x_train_index[35000:], y_train_categorical[35000:]), callbacks=[tensorflow.keras.callbacks.TensorBoard(log_dir), hp.KerasCallback(log_dir, hparams)])\n",
    "    y_pred = model.predict(x_test_index)\n",
    "    print(classification_report(y_test, np.argmax(y_pred, axis=1).astype(\"float32\")))\n",
    "    _, accuracy = model.evaluate(x_test_index, y_test_categorical)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tensorflow.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        accuracy = train_test_model(hparams)\n",
    "        tensorflow.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "esecuzione:  0\n",
      "{'learning_rate': 0.005}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 45s 154ms/step - loss: 0.6943 - accuracy: 0.4878 - val_loss: 0.6935 - val_accuracy: 0.4906\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 42s 152ms/step - loss: 0.6933 - accuracy: 0.5054 - val_loss: 0.6930 - val_accuracy: 0.5208\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 40s 147ms/step - loss: 0.6928 - accuracy: 0.5283 - val_loss: 0.6926 - val_accuracy: 0.5356\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 41s 151ms/step - loss: 0.6924 - accuracy: 0.5433 - val_loss: 0.6922 - val_accuracy: 0.5499\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 40s 148ms/step - loss: 0.6920 - accuracy: 0.5488 - val_loss: 0.6918 - val_accuracy: 0.5630\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 40s 146ms/step - loss: 0.6916 - accuracy: 0.5681 - val_loss: 0.6914 - val_accuracy: 0.5707\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 41s 151ms/step - loss: 0.6912 - accuracy: 0.5779 - val_loss: 0.6909 - val_accuracy: 0.5858\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 42s 152ms/step - loss: 0.6908 - accuracy: 0.5925 - val_loss: 0.6905 - val_accuracy: 0.5945\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 41s 150ms/step - loss: 0.6904 - accuracy: 0.5992 - val_loss: 0.6900 - val_accuracy: 0.6130\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 42s 152ms/step - loss: 0.6899 - accuracy: 0.5974 - val_loss: 0.6895 - val_accuracy: 0.6277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.65      2479\n",
      "           1       0.65      0.55      0.60      2521\n",
      "\n",
      "    accuracy                           0.62      5000\n",
      "   macro avg       0.63      0.62      0.62      5000\n",
      "weighted avg       0.63      0.62      0.62      5000\n",
      "\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.6897 - accuracy: 0.6238\n",
      "esecuzione:  1\n",
      "{'learning_rate': 0.01}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 50s 170ms/step - loss: 0.6965 - accuracy: 0.5291 - val_loss: 0.6918 - val_accuracy: 0.5399\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 42s 153ms/step - loss: 0.6907 - accuracy: 0.5673 - val_loss: 0.6894 - val_accuracy: 0.5911\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 38s 139ms/step - loss: 0.6884 - accuracy: 0.6043 - val_loss: 0.6870 - val_accuracy: 0.6225\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 39s 142ms/step - loss: 0.6861 - accuracy: 0.6279 - val_loss: 0.6844 - val_accuracy: 0.6519\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 38s 139ms/step - loss: 0.6834 - accuracy: 0.6477 - val_loss: 0.6812 - val_accuracy: 0.6666\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 39s 141ms/step - loss: 0.6801 - accuracy: 0.6621 - val_loss: 0.6774 - val_accuracy: 0.6817\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 39s 142ms/step - loss: 0.6761 - accuracy: 0.6770 - val_loss: 0.6727 - val_accuracy: 0.6885\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 39s 141ms/step - loss: 0.6708 - accuracy: 0.6823 - val_loss: 0.6663 - val_accuracy: 0.6951\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 39s 142ms/step - loss: 0.6638 - accuracy: 0.6898 - val_loss: 0.6577 - val_accuracy: 0.6993\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 43s 157ms/step - loss: 0.6544 - accuracy: 0.6955 - val_loss: 0.6466 - val_accuracy: 0.6999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.80      0.72      2479\n",
      "           1       0.75      0.58      0.66      2521\n",
      "\n",
      "    accuracy                           0.69      5000\n",
      "   macro avg       0.70      0.69      0.69      5000\n",
      "weighted avg       0.70      0.69      0.69      5000\n",
      "\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 0.6476 - accuracy: 0.6928\n",
      "esecuzione:  2\n",
      "{'learning_rate': 0.015}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 46s 156ms/step - loss: 0.6938 - accuracy: 0.5131 - val_loss: 0.6920 - val_accuracy: 0.5246\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 44s 159ms/step - loss: 0.6913 - accuracy: 0.5365 - val_loss: 0.6898 - val_accuracy: 0.5559\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 43s 156ms/step - loss: 0.6892 - accuracy: 0.5679 - val_loss: 0.6873 - val_accuracy: 0.5826\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 42s 153ms/step - loss: 0.6867 - accuracy: 0.5940 - val_loss: 0.6845 - val_accuracy: 0.6199\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 42s 152ms/step - loss: 0.6836 - accuracy: 0.6221 - val_loss: 0.6804 - val_accuracy: 0.6437\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 40s 147ms/step - loss: 0.6793 - accuracy: 0.6354 - val_loss: 0.6750 - val_accuracy: 0.6556\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 40s 147ms/step - loss: 0.6731 - accuracy: 0.6463 - val_loss: 0.6673 - val_accuracy: 0.6528\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 41s 148ms/step - loss: 0.6642 - accuracy: 0.6525 - val_loss: 0.6555 - val_accuracy: 0.6754\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 40s 146ms/step - loss: 0.6511 - accuracy: 0.6667 - val_loss: 0.6383 - val_accuracy: 0.6832\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 34s 125ms/step - loss: 0.6321 - accuracy: 0.6783 - val_loss: 0.6146 - val_accuracy: 0.6921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71      2479\n",
      "           1       0.72      0.63      0.68      2521\n",
      "\n",
      "    accuracy                           0.69      5000\n",
      "   macro avg       0.70      0.69      0.69      5000\n",
      "weighted avg       0.70      0.69      0.69      5000\n",
      "\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 0.6159 - accuracy: 0.6934\n",
      "esecuzione:  3\n",
      "{'learning_rate': 0.02}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 36s 122ms/step - loss: 0.6909 - accuracy: 0.5479 - val_loss: 0.6886 - val_accuracy: 0.5818\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 31s 113ms/step - loss: 0.6863 - accuracy: 0.5981 - val_loss: 0.6833 - val_accuracy: 0.6433\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 31s 112ms/step - loss: 0.6804 - accuracy: 0.6387 - val_loss: 0.6767 - val_accuracy: 0.5971\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 31s 111ms/step - loss: 0.6712 - accuracy: 0.6669 - val_loss: 0.6635 - val_accuracy: 0.6884\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 31s 112ms/step - loss: 0.6554 - accuracy: 0.6865 - val_loss: 0.6427 - val_accuracy: 0.6981\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 31s 112ms/step - loss: 0.6302 - accuracy: 0.6992 - val_loss: 0.6143 - val_accuracy: 0.6819\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 31s 113ms/step - loss: 0.5951 - accuracy: 0.7128 - val_loss: 0.5708 - val_accuracy: 0.7245\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 31s 115ms/step - loss: 0.5591 - accuracy: 0.7260 - val_loss: 0.5402 - val_accuracy: 0.7353\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 32s 116ms/step - loss: 0.5343 - accuracy: 0.7400 - val_loss: 0.5229 - val_accuracy: 0.7451\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 32s 119ms/step - loss: 0.5139 - accuracy: 0.7533 - val_loss: 0.4999 - val_accuracy: 0.7590\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      2479\n",
      "           1       0.77      0.76      0.76      2521\n",
      "\n",
      "    accuracy                           0.76      5000\n",
      "   macro avg       0.76      0.76      0.76      5000\n",
      "weighted avg       0.76      0.76      0.76      5000\n",
      "\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.4961 - accuracy: 0.7618\n",
      "esecuzione:  4\n",
      "{'learning_rate': 0.05}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 39s 131ms/step - loss: 0.6893 - accuracy: 0.5623 - val_loss: 0.6822 - val_accuracy: 0.5895\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 33s 120ms/step - loss: 0.6709 - accuracy: 0.6420 - val_loss: 0.6520 - val_accuracy: 0.6713\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 32s 116ms/step - loss: 0.6194 - accuracy: 0.6857 - val_loss: 0.5686 - val_accuracy: 0.7205\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 32s 116ms/step - loss: 0.5474 - accuracy: 0.7295 - val_loss: 0.5160 - val_accuracy: 0.7479\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 32s 115ms/step - loss: 0.5185 - accuracy: 0.7466 - val_loss: 0.5590 - val_accuracy: 0.7131\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 32s 116ms/step - loss: 0.4817 - accuracy: 0.7732 - val_loss: 0.6233 - val_accuracy: 0.6832\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 32s 116ms/step - loss: 0.4581 - accuracy: 0.7859 - val_loss: 0.4311 - val_accuracy: 0.7962\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 32s 116ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.4348 - val_accuracy: 0.8021\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 32s 117ms/step - loss: 0.4306 - accuracy: 0.8010 - val_loss: 0.4089 - val_accuracy: 0.8145\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 32s 115ms/step - loss: 0.4186 - accuracy: 0.8102 - val_loss: 0.4095 - val_accuracy: 0.8076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83      2479\n",
      "           1       0.87      0.75      0.80      2521\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.82      0.82      0.82      5000\n",
      "weighted avg       0.82      0.82      0.82      5000\n",
      "\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.4149 - accuracy: 0.8164\n",
      "esecuzione:  5\n",
      "{'learning_rate': 0.1}\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 37s 124ms/step - loss: 0.6711 - accuracy: 0.6290 - val_loss: 0.6329 - val_accuracy: 0.6318\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 32s 116ms/step - loss: 0.5831 - accuracy: 0.6968 - val_loss: 0.5892 - val_accuracy: 0.6815\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 32s 116ms/step - loss: 0.5253 - accuracy: 0.7402 - val_loss: 0.4706 - val_accuracy: 0.7786\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 32s 118ms/step - loss: 0.4727 - accuracy: 0.7768 - val_loss: 0.5356 - val_accuracy: 0.7346\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 32s 117ms/step - loss: 0.4406 - accuracy: 0.7979 - val_loss: 0.4003 - val_accuracy: 0.8187\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 32s 116ms/step - loss: 0.4170 - accuracy: 0.8101 - val_loss: 0.4305 - val_accuracy: 0.8004\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 31s 115ms/step - loss: 0.4000 - accuracy: 0.8207 - val_loss: 0.3745 - val_accuracy: 0.8344\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 31s 114ms/step - loss: 0.3930 - accuracy: 0.8237 - val_loss: 0.3780 - val_accuracy: 0.8310\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 32s 115ms/step - loss: 0.3780 - accuracy: 0.8326 - val_loss: 0.3705 - val_accuracy: 0.8341\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 32s 115ms/step - loss: 0.3705 - accuracy: 0.8380 - val_loss: 0.4135 - val_accuracy: 0.8139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.79      2479\n",
      "           1       0.76      0.94      0.84      2521\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.84      0.82      0.82      5000\n",
      "weighted avg       0.84      0.82      0.82      5000\n",
      "\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 0.4060 - accuracy: 0.8196\n"
     ]
    }
   ],
   "source": [
    "n_esecuzione = 0\n",
    "for lr in HP_LEARNING_RATE.domain.values:\n",
    "    hparams = {\n",
    "        HP_LEARNING_RATE: lr,\n",
    "    }\n",
    "    print(\"esecuzione: \", n_esecuzione)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    run(log_dir + \"/esecuzione_{}\".format(n_esecuzione), hparams)\n",
    "    n_esecuzione += 1 "
   ]
  }
 ]
}