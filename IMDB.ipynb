{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0799eb0fd45bbf32cd22b7eb12315f66a6945dddec75ab4ee4de6611b037c6c79",
   "display_name": "Python 3.8.5 64-bit ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "799eb0fd45bbf32cd22b7eb12315f66a6945dddec75ab4ee4de6611b037c6c79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Fase di import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pre_processing as pp"
   ]
  },
  {
   "source": [
    "## Lettura dataset IMDB avente il seguente formato: review,sentiment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset/IMDB.csv\", sep=\",\", header=0)"
   ]
  },
  {
   "source": [
    "## Analisi dataset fornito in input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dimensione dataset:  50000\nSentimenti all'interno del dataset:  ['positive' 'negative']\nNumero di elementi nulli:\n review       0\nsentiment    0\ndtype: int64\nNumero di elementi positivi:  50.0 %\nNumero di elementi negativi:  50.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensione dataset: \", len(dataset))\n",
    "print(\"Sentimenti all'interno del dataset: \", dataset[\"sentiment\"].unique())\n",
    "print(\"Numero di elementi nulli:\\n\", dataset.isnull().sum())\n",
    "print(\"Numero di elementi positivi: \", (len(dataset[\"sentiment\"][dataset.sentiment == \"positive\"])/len(dataset))*100, \"%\")\n",
    "print(\"Numero di elementi negativi: \", (len(dataset[\"sentiment\"][dataset.sentiment == \"negative\"])/len(dataset))*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = "
   ]
  },
  {
   "source": [
    "Come riportato dall'articolo fornito per il progetto, la fase di weight initialization viene fatta utilizzando il modello pre-addestrato GloVe\n",
    "\n",
    "https://www.aclweb.org/anthology/D14-1162.pdf"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creazione_modello_GloVe(filename):\n",
    "    f = open(filename, encoding=\"utf8\")\n",
    "    embeding_index = {}\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embeding_index[word] = coefs\n",
    "    f.close()\n",
    "    return embeding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = creazione_modello_GloVe(\"dataset/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "400000\n[-0.25522  -0.75249  -0.86655   1.1197    0.12887   1.0121   -0.57249\n -0.36224   0.44341  -0.12211   0.073524  0.21387   0.96744  -0.068611\n  0.51452  -0.053425 -0.21966   0.23012   1.043    -0.77016  -0.16753\n -1.0952    0.24837   0.20019  -0.40866  -0.48037   0.10674   0.5316\n  1.111    -0.19322   1.4768   -0.51783  -0.79569   1.7971   -0.33392\n -0.14545  -1.5454    0.0135    0.10684  -0.30722  -0.54572   0.38938\n  0.24659  -0.85166   0.54966   0.82679  -0.68081  -0.77864  -0.028242\n -0.82872 ]\n"
     ]
    }
   ],
   "source": [
    "print(len(embedding))\n",
    "print(embedding[\"banana\"])"
   ]
  }
 ]
}